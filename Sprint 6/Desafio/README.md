<h1 align="center">Resolu√ß√£o do Desafio ‚úçÔ∏è</h1>

### üìù Explica√ß√£o sobre o desafio

O objetivo deste desafio √© iniciar o desafio final do programa de bolsas. O primeiro passo consiste em formular perguntas para a base de dados, de modo que todo o restante do desafio final seja orientado por essas quest√µes. Em seguida, iniciamos o desafio propriamente dito com a ingest√£o dos arquivos CSV. Esses arquivos s√£o armazenados em um Bucket Amazon S3 na Raw Zone, utilizando um c√≥digo Python executado em um container Docker para transferir os dados locais para a nuvem.

### Minhas Perguntas

1. Quais s√£o os filmes de crime/guerra com as maiores notas m√©dias?
    Motivo: Identificar quais filmes do g√™nero crime/guerra receberam as melhores avalia√ß√µes.


2. Qual o tempo m√©dio de dura√ß√£o dos filmes de crime/guerra lan√ßados entre 2000 e 2020?
    Motivo: Analisar a tend√™ncia de dura√ß√£o dos filmes desse g√™nero ao longo dos anos.


3. Quais artistas fizeram mais series de crime/guerra e quais personagens eles interpretaram?
    Motivo: Descobrir artistas influentes no g√™nero e seus pap√©is t√≠picos.


4. H√° correla√ß√£o entre o n√∫mero de votos que um filme de crime/guerra recebe e sua nota m√©dia?
    Motivo: Analisar se filmes mais votados tendem a ter notas mais altas ou baixas.


5. Quais s√£o as s√©ries de crime/guerra mais conhecidos de cada d√©cada?
    Motivo: Identificar t√≠tulos de destaque em diferentes per√≠odos

### Script Python

- O objetivo do [Script Python](./S3.py) foi criar um bucket com RAW zone e armazenar os arquivos "movies.csv" e "series.csv" nele.

- O primeiro passo para isso foi importar a biblioteca boto3, respons√°vel por interagir com os servi√ßos da AWS atrav√©s do python.

- Com a biblioteca boto3 importada, foi poss√≠vel criar um cliente boto3, que interaja com o servi√ßo AWS S3, utilizando o m√©todo ``.client()``. 
    - C√≥digo da cria√ß√£o do boto3 client
        - ````
            s3 = boto3.client(
                's3',
                aws_access_key_id = AWS_ACCESS_KEY_ID,
                aws_secret_access_key = AWS_SECRET_ACCESS_KEY,
                aws_session_token = AWS_SESSION_TOKEN
            )
            ````
    ###
- Ap√≥s a cria√ß√£o do cliente, foi poss√≠vel desenvolver a fun√ß√£o que cria o bucket S3. Essa fun√ß√£o exige como argumento o nome do bucket a ser criado, que √© um requisito obrigat√≥rio. Al√©m disso, utilizei o ``try excepet`` para tratar os erros e exibir uma mensagem no caso de sucesso.
    - C√≥digo da fun√ß√£o que cria o bucket S3
        - ````
            def create_bucket(bucket_name):
                try:
                    s3.create_bucket(Bucket= bucket_name)
                except Exception as error:
                    print(f"N√£o foi poss√≠vel criar o Bucket: {error}")
                else:
                    print(f"Bucket {bucket_name} criado com sucesso!")
            ````
###
- Com o bucket cirado, foi poss√≠vel desenvolver a fun√ß√£o que faz o upload dos arquivos para o S3. Essa fun√ß√£o exige como argumento o caminho do arquivo que sofrer√° upload, o nome do bucket no qual o arquivo ser√° armazenado e com qual nome o arquivo ir√° ficar no bucket. Al√©m disso, utilizei o ``try excepet`` para tratar os erros e exibir uma mensagem no caso de sucesso.
    - C√≥digo da fun√ß√£o que faz upload do arquivo.
         - ````
            def upload_to_s3(path, bucket_name, file_name):
                try:
                    s3.upload_file(path, bucket_name, file_name)
                except Exception as error:
                    print(f"Erro ao upar arquivo: {error}")
                else:
                    print(f"Arquivo '{file_name}' upado para o bucket '{bucket_name}' com sucesso!")

            ````
###
- Com ambas as fun√ß√µes criadas, primeiramente invoquei a ``create_bucket()`` para criar o bucket S3
    - C√≥digo da cria√ß√£o do bucket:
        - ````
            bucket_name = "data-lake-arthur-theodoro"
            create_bucket(bucket_name)
            ``````
###
- Ap√≥s criar o bucket, fiz o upload dos arquivos para o S3 usando a fun√ß√£o ``upload_to_s3``, seguindo a estrutura da Raw Zone, que requer uma organiza√ß√£o espec√≠fica de pastas incluindo a data do sistema no momento do upload. Para obter a data atual, utilizei o m√©todo ``now()`` da biblioteca datetime e, para format√°-la conforme necess√°rio, usei o m√©todo ``strftime()`` da mesma biblioteca.
    - C√≥digo do upload dos arquivos:
        - ``````
            #Definindo nome das pastas para upar os arquivos
            hoje = dt.datetime.now().strftime("%Y/%m/%d")
            pastas_movies = f"Raw/Local/CSV/Movies/{hoje}"
            pastas_series = f"Raw/Local/CSV/Series/{hoje}"

            #Upando arquivo movies.csv
            upload_to_s3(r"/app/data/movies.csv", bucket_name, f"{pastas_movies}/movies.csv")

            #Upando arquivo series.csv
            upload_to_s3(r"/app/data/series.csv", bucket_name, f"{pastas_series}/series.csv")
            ``````

### Docker

- Com o Script python criado, foi necess√°rio criar uma imagem e um container no Docker com um volume para armazenar os arquivos CSV e executar o processo Python implementado.

 - C√≥digo respons√°vel pela cria√ß√£o da imagem: [Dockerfile](./Dockerfile)
 
 - Segue a explica√ß√£o linha por linha do arquivo Dockerfile, respons√°vel por criar a imagem
    - ```` 
        FROM python
        ````
        - Essa linha especifica a imagem base que ser√° utilizada para criar a nova imagem Docker, que no caso √© a imagem oficial do Python pois o arquivo que ser√° executado √© um .py
    
    - ```` 
        WORKDIR /app 
        ````
        - Essa linha cria o diret√≥rio de trabalho "/app" dentro do container que executar essa imagem

    - ```` 
        COPY COPY S3.py .
        ````
        - Essa linha √© respons√°vel por criar uma c√≥pia do arquivo "S3.py" para dentro do diret√≥rio "/app" criado anteriormente

    - ````
        RUN pip install boto3 
        ``````
        - Essa linha √© respons√°vel por instalar a biblioteca boto3 no ambiente docker que ser√° criado

    - ```` 
        CMD ["python", "S3.py"]
        ````
        - Essa linha √© a respons√°vel por efetivamente executar o arquivo "S3.py". Ela executa  primeito o interpretador python, para ap√≥s isso rodar o arquivo desejado.

###

- Ap√≥s a cria√ß√£o do arquivo Dockerfile acima, foi necess√°rio a utilizar o comando ``docker build`` no terminal para efetivamente criar a imagem

    - Evid√™ncia da execu√ß√£o do comando docker build
    ![Imagem da execu√ß√£o do comando docker build](../Evidencias/CriacaoImagem.png)
    - no caso, utilizei a flag -t para dar um nome a imagem. O "." no final da linha representa que o Docker deve usar o Dockerfile localizado no diret√≥rio atual para construir a imagem.

###

- Ap√≥s a cria√ß√£o da imagem e antes da cria√ß√£o do container, utilizei o comando ``docker volume create`` para criar um volume docker, respons√°vel por armazenar os arquivos que ser√£o lidos pelo script python
    - Evid√™ncia da cria√ß√£o do volume
    ![cria√ß√£o do volume](../Evidencias/CriandoVolume.png)
 #### Executando um container a partir da imagem criada

- Com a imagem e o volume criados, foi poss√≠vel executar um container utilizando-os.
    - Evid√™ncia da execu√ß√£o do container a partir da imagem "executar-script-s3"
        - ![Imagem da execu√ß√£o do container a partir da imagem executar-script-s3](../Evidencias/ExecutandoContainer.png)
    - A sa√≠da da execu√ß√£o representa que o arquivo "executar-script-s3" foi executado com sucesso.

###
- Com a execu√ß√£o correta do script python, um bucket S3 foi criado e os arquivos foram upados para ele, seguindo a estrutura da Raw Zone.

    - Evid√™ncia da cria√ß√£o do bucket:
    ![imagem da cria√ß√£o correta do bucket](../Evidencias/BucketCriado.png)
    - Evid√™ncia do arquivo "movies.csv" upado para o bucket seguindo a estrutura Raw Zone
    ![imagem do arquivo "movies.csv" no bucket](../Evidencias/ArquivoMoviesRaw.png)
    - Evid√™ncia do arquivo "series.csv" upado para o bucket seguindo a estrutura Raw Zone
    ![imagem do arquivo "series.csv" no bucket](../Evidencias/ArquivoSeriesRaw.png)